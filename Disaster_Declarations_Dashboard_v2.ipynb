{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d160c636",
   "metadata": {},
   "source": [
    "<style>\n",
    "    h1 {\n",
    "        margin-bottom: -.5em;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "# FEMA Disaster Declarations Summaries Dashboard Update Notebook\n",
    "### An ArcGIS Notebook leveraging the ArcGIS API for Python to automatically update a FEMA-derived custom Dashboard dataset\n",
    "By Misti Wudtke | misti@aldermaps.com | Portfolio: [aldermaps.com](https://aldermaps.com)\n",
    "\n",
    "This ArcGIS Notebook is the data update component of my [FEMA Disaster Declaration Summaries ArcGIS Dashboard](https://disasterdeclarations.aldermaps.com/). \n",
    "\n",
    "The Notebook runs automatically once per day via a scheduled Task in ArcGIS Online. It connects to openFEMA's API and accesses [FEMA's Disaster Declaration Summaries (v2)](https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2), comparing the most recent Summaries with the Summaries that have already been processed and included in the Dashboard. Any new (by declarationDate) Summaries are processed by the Notebook and added to the Dashboard's Declarations Summaries feature layer.\n",
    "\n",
    "FEMA's Disaster Declaration Summaries comprise multiple rows/observations for a given Disaster Declaration String (e.g., EM-3454-WI), one row/observation for every entity (usually, a county or tribal area, but occassionally an entire state). This Notebook's processing primarily consists of dissolving the boundaries of multiple FEMA Declaration strings. In other words, a single FEMA Declaration String is represented by one _or more_ rows (e.g. counties) in FEMA's data, whereas in this Dashbaord and its underlying data, a single FEMA Declaration String is represented by a single row/geometry. Note that a row's geometry may not be contiguous, i.e. it may comprise a multipart feature.\n",
    "\n",
    "An exception to this data organization paradigm is FEMA Declaration Strings that encompass multiple entities (e.g., a Declaration string with rows applying to both counties and tribal areas). In this case, a separate row/geometry is created for each Declaration String/entity combination. Different entities (state, county, tribal area) may be viewed separately within the Dashboard via the filter in the Dashboard header.\n",
    "\n",
    "The data is summarized at the Declaration String level both to facilitate analysis of spatiotemporal patterns in Disaster Declarations Summaries, and for performance reasons.\n",
    "\n",
    "The ArcGIS Online Dashboard and its components (web map, feature layers) are publicly available, along with this Dashboard, for use by anyone for anything.\n",
    "\n",
    "* [ArcGIS Dashboard](https://alder.maps.arcgis.com/apps/dashboards/c38d501975e94300a4b53724ff0f8cc8)\n",
    "* [Dashboard Web Map](https://alder.maps.arcgis.com/apps/mapviewer/index.html?webmap=8b9bb0580a49458a8d1592c9d78f9b85)\n",
    "* [Dashboard Feature Layer (includes Summaries & Geometries layers)](https://alder.maps.arcgis.com/home/item.html?id=d37c3c2a6f1c4586baad82828bfc3c59)\n",
    "* [Notebook (ArcGIS Online)](https://alder.maps.arcgis.com/home/item.html?id=31caad975e8348a2bc9406825b958436)\n",
    "* [Notebook (GitHub)](https://github.com/AlderMaps/arcgis-api-python/blob/main/Disaster_Declarations_Dashboard.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49e7b25",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc57611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor # for converting to sdf\n",
    "from arcgis.features import manage_data # For dissolving declaration boundaries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "warnings.simplefilter(\"ignore\", InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf825fb0",
   "metadata": {},
   "source": [
    "### Connect to ArcGIS\n",
    "\"me\" and \"my_email\" variables will be used to send an email at script completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4041c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS(\"home\")\n",
    "me = gis.properties.user.username\n",
    "\n",
    "print(f\"Logged in as {me} successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb1661",
   "metadata": {},
   "source": [
    "## Part I: Check for new FEMA Disaster Declarations Summaries records\n",
    "\n",
    "The first section of the notebook loads the necessary datasets and compares them to see whether new Disaster Declaration Summaries have been added by FEMA since the Notebook was last run.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122050f6",
   "metadata": {},
   "source": [
    "### Get Dashboard feature layers (Geometries and Summaries)\n",
    "\n",
    "The Notebook uses two feature layers (published in a [single feature layer collection](https://alder.maps.arcgis.com/home/item.html?id=d37c3c2a6f1c4586baad82828bfc3c59)):\n",
    "\n",
    "* The input or \"geometries\" layer, which the script references to retrieve feature geometries associated with Declaration Summary rows.\n",
    "* The output or \"dashboard\" layer, to which the dissolved summary geometries are written. This is the layer that actually appears in the Dashboard.\n",
    "\n",
    "Both layers are retrieved and converted to spatial data frames (sdf) to facilitate processing with the summaries data from fema, also a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_id = \"d37c3c2a6f1c4586baad82828bfc3c59\"\n",
    "dd_item = gis.content.get(dd_id)\n",
    "geometries_layer = dd_item.layers[1]\n",
    "geometries_sdf = pd.DataFrame.spatial.from_layer(geometries_layer)\n",
    "\n",
    "# Production layer; commented out while testing\n",
    "#dashboard_layer = dd_item.layers[0]\n",
    "\n",
    "# Test layer; replace with above on conversion to production\n",
    "test_id = \"edb716da51bc4f7882d13d425ad08fd2\"\n",
    "test_item = gis.content.get(test_id)\n",
    "dashboard_layer = test_item.layers[0]\n",
    "dashboard_sdf = pd.DataFrame.spatial.from_layer(dashboard_layer)\n",
    "\n",
    "print(\"Geometry and dashboard feature layers loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f379d3",
   "metadata": {},
   "source": [
    "### Hit openFEMA API; convert response to Pandas Dataframe\n",
    "\n",
    "I have not altered the default number of records returned by the API, which is 1000.\n",
    "\n",
    "Two filters are applied to the API URL:\n",
    "\n",
    "* \"fyDeclared ge 2013\" : Return only values from the field fyDeclared (Fiscal Year Declared) greater than or equal to 2013\n",
    "    * _(This filter ensures the declarations match the temporal range of the records in my geometries reference layer)_\n",
    "* \"orderby=declarationDate desc\" : Order the results (descending) by the declarationDate field ensures the most recent records are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = r\"https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries?$filter=fyDeclared ge 2013&$orderby=declarationDate desc\"\n",
    "\n",
    "response = requests.get(api_url)\n",
    "data = response.json()\n",
    "summaries_df = pd.DataFrame(data[\"DisasterDeclarationsSummaries\"])\n",
    "\n",
    "print(\"Most recent 1000 Disaster Declarations Summaries loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e042708",
   "metadata": {},
   "source": [
    "### Add and calculate \"Entity\" field in Summaries dataframe\n",
    "\n",
    "As described above, this Notebook rolls up FEMA Disaster Declarations Summaries into a single row per FEMA Declaration String + Entity (e.g. county, tribal area) combination. In the Summaries dataset, \"Entity\" as I have defined it for the purpose of my dataset is defined by multiple fields:\n",
    "\n",
    "* \"Entity\" is \"County or Equivalent\" if the field \"fipsCountyCode\" _is not_ \"000\"\n",
    "* \"Entity\" is \"Tribal Area or Equivalent\" if the field \"designatedArea\" _is not_ \"Statewide\" AND the field \"fipsCountyCode\" is \"000\"\n",
    "* \"Entity\" is \"Statewide\" if the field \"designatedArea\" is \"Statewide\"\n",
    "\n",
    "(See [FEMA's description of the fipsCountyCode field](https://www.fema.gov/openfema-data-page/disaster-declarations-summaries-v2#:~:text=FIPS%20three%2Ddigit,cannot%20be%20entered.) for more information on why the above is true.)\n",
    "\n",
    "The addition and calculation of the Entity field both enables the ability to check for new rows from FEMA, and provides a single field to filter by Entity in the header of the Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bd54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_conditions = [\n",
    "    summaries_df[\"fipsCountyCode\"] != \"000\",\n",
    "    (summaries_df[\"fipsCountyCode\"] == \"000\") & (summaries_df[\"designatedArea\"] != \"Statewide\"),\n",
    "    summaries_df[\"designatedArea\"] == \"Statewide\"\n",
    "]\n",
    "\n",
    "entity_values = [\"County or Equivalent\", \"Tribal Area or Equivalent\", \"State or Equivalent\"]\n",
    "\n",
    "summaries_df[\"Entity\"] = np.select(entity_conditions, entity_values)\n",
    "\n",
    "print(\"Entity field addition completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09eff43",
   "metadata": {},
   "source": [
    "### Check whether there are new Disaster Declaration Summaries to be added (not already in the Dashboard)\n",
    "\n",
    "The Summaries dataframe is compared with the dataframe of records already in the Dashboard (comparison on the two fields \"femaDeclarationString\" and \"Entity\"). This is accomplished with a multi-key anti-join. If all Summaries records are matched to a record in the Dashboard, then there are no new records to process, and the Notebook effectively stops with this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f171ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_key = [\"femaDeclarationString\", \"Entity\"]\n",
    "\n",
    "# Merge the dataframes on the multikey fields\n",
    "pre_adds = summaries_df.merge(dashboard_sdf[multi_key], on=multi_key, how=\"left\", indicator=True)\n",
    "\n",
    "# Filter the results to those rows only occurring in the summaries dataset, not in the dashboard\n",
    "adds_df = pre_adds[pre_adds[\"_merge\"] == \"left_only\"].drop(columns=[\"_merge\"])\n",
    "\n",
    "if adds_df.empty:\n",
    "    adds = False\n",
    "    print(\"Found no new Declarations to add! We're done here.\")\n",
    "else:\n",
    "    adds = True\n",
    "    print(\"Found rows to add:\\n\")\n",
    "    print(f\"adds designatedAreas: {adds_df[['designatedArea', 'state']]}\")\n",
    "    print(\"\\nProceeding to the rest of the Notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af8968",
   "metadata": {},
   "source": [
    "## Part II: Process new FEMA Declaration records and append to existing Dashboard dataset\n",
    "\n",
    "The code in the second half of the Notebook only execute if new records were found in the call to the FEMA API.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1326111",
   "metadata": {},
   "source": [
    "### Add and calculate additional fields in the Summaries dataframe for use in merge\n",
    "\n",
    "\"fipsFullCode\" and \"fipsTribalCode fields: The addition of a full five-digit FIPS code enables a single-column comparison of rows between Summaries and the Dashboard dataframes\n",
    "\n",
    "\"COVID19\": This field enables the COVID-19 filter in the Dashboard header, allowing the user to view only COVID, only non-COVID, or all Summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adds:\n",
    "\n",
    "    # Add & calculate FIPS & Tribal FIPS fields\n",
    "    adds_df[\"fipsFullCode\"] = adds_df[\"fipsStateCode\"] + adds_df[\"fipsCountyCode\"]\n",
    "    adds_df[\"fipsTribalCode\"] = adds_df[\"fipsStateCode\"] + adds_df[\"placeCode\"]\n",
    "\n",
    "    # Add & calculate COVID-19 field\n",
    "    adds_df[\"COVID19\"] = np.where(adds_df[\"declarationTitle\"].str.contains(\"COVID-19\"), \"Show only COVID-19\", \"Show only non-COVID-19\")\n",
    "\n",
    "    print(\"Field additions completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56cf227",
   "metadata": {},
   "source": [
    "### Convert all pseudo-date fields in Summaries dataframe from string/object to true datetime\n",
    "\n",
    "All other potentially troublesome fields (e.g. FIPS) were checked in preliminary analysis and determined to be the correct data types (object/string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46caf1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adds:\n",
    "\n",
    "    date_columns = [\"declarationDate\", \"incidentBeginDate\", \"incidentEndDate\", \"disasterCloseoutDate\", \"lastIAFilingDate\", \"lastRefresh\"]\n",
    "\n",
    "    for dc in date_columns:\n",
    "        adds_df[dc] = pd.to_datetime(adds_df[dc], errors=\"coerce\")\n",
    "\n",
    "    print(\"Field conversion to datetime completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d26e2f",
   "metadata": {},
   "source": [
    "### Set up variables and field mappings dictionary for use in get_geometries function\n",
    "\n",
    "The Fema Disaster Declaration Summaries retrieved fromm openFEMA's API do not include geometry and cannot be displayed directly on a map. To portray the data on a map, county (or tribal area, state) geometry data must be associated with each record. The spatially enabled dataframe geometries_sdf, created above, contains these geometries.\n",
    "\n",
    "Each row in the Summaries dataframe will be matched with its corresponding geometry in the geometries dataframe. For counties, the full five-digit FIPS code is used; for states, the two-digit State FIPS is used, and for tribal areas a tribal code is used. The names of the key fields in both datasets are set up below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea13b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adds:\n",
    "\n",
    "    state = \"State or Equivalent\"\n",
    "    county = \"County or Equivalent\"\n",
    "    tribal = \"Tribal Area or Equivalent\" \n",
    "\n",
    "    state_field = \"State_FIPS\"\n",
    "    county_field = \"Full_FIPS\"\n",
    "    tribal_field1 = \"AIANNHFP1\"\n",
    "    tribal_field2 = \"AIANNHFP2\"\n",
    "    tribal_field3 = \"AIANNHFP3\"\n",
    "\n",
    "    key_fields_dict = {\n",
    "        \"State_FIPS\": \"fipsStateCode\",\n",
    "        \"Full_FIPS\": \"fipsFullCode\",\n",
    "        \"AIANNHFP1\": \"fipsTribalCode\",\n",
    "        \"AIANNHFP2\": \"fipsTribalCode\",\n",
    "        \"AIANNHFP3\": \"fipsTribalCode\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515e5e4",
   "metadata": {},
   "source": [
    "### Associate Summaries records with their correct geometries\n",
    "\n",
    "In this step the FEMA Summaries records retrieved from the API are merged with their corresponding geometries. The merge method is incorporated in a function because its parameters are different fields, depending on the entity (e.g. counties merge on 5-digit FIPS, states on 2-digit FIPS).\n",
    "\n",
    "First the adds dataframe is filtered to the relevent entity, then the merge is performed. The Tribal geometries data (from US Census Bureau) includes three different fields that correspond to the Summaries \"placeCode\" field, and the Summaries rows can and do potentially utilize any of these three identifiers. Therefore the Tribal Area Entities must be considered three times.\n",
    "\n",
    "Finally, all merged dataframes are assembled vertically into a single adds dataframe including geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c85969",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adds:\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    def get_geometries(entity, field, df_list):\n",
    "\n",
    "        # Filter the adds_df to the entity (county, tribal or state) argument\n",
    "        entity_adds_df = adds_df[adds_df[\"Entity\"] == entity]\n",
    "\n",
    "        # If there are rows in the adds_df for this particular entity:\n",
    "        if not entity_adds_df.empty:\n",
    "            # The suffixes argument must be included, with one element of the tuple parameter being an empty string.\n",
    "            # Otherwise the dissolve will fail because both \"Entity\" fields are renamed to the defaults of \"Entity_x\" and \"Entity_y\".\n",
    "            merged = entity_adds_df.merge(geometries_sdf, left_on=[key_fields_dict[field]], right_on=field, suffixes=('', '_2'))\n",
    "            df_list.append(merged)\n",
    "\n",
    "    get_geometries(state, state_field, df_list)\n",
    "    get_geometries(county, county_field, df_list)\n",
    "    get_geometries(tribal, tribal_field1, df_list)\n",
    "    get_geometries(tribal, tribal_field2, df_list)\n",
    "    get_geometries(tribal, tribal_field3, df_list)\n",
    "\n",
    "    # Ignore index is required here, else the conversion to feature collection below fails\n",
    "    adds_geometries = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    print(\"Geometry incorporation completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a955b",
   "metadata": {},
   "source": [
    "### Aggregate Summaries rows to FEMA Declaration String / Entity level\n",
    "\n",
    "I now have new / to add Summaries data but it is still at the county level. This cell aggregates both the rows and the associated geometry to the level of the FEMA Declaration String (and Entity field). This is accomplished with the ArcGIS API for Python dissolve_boundaries method. The fields used in the dissolve are derived from the fields present in the current Dashboard layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adds:\n",
    "\n",
    "    # Convert the spatial dataframe to a feature collection,\n",
    "    # the required input type for dissolve_boundaries.\n",
    "    adds_feature_collection = adds_geometries.spatial.to_feature_collection()\n",
    "\n",
    "    # Assemble field names to use in dissolve_boundaries from destination layer minus shape/id fields.\n",
    "    remove_fields = [\"OBJECTID\", \"Shape__Area\", \"Shape__Length\", \"SHAPE\"]\n",
    "    dissolve_fields = [f[\"name\"] for f in dashboard_layer.properties.fields if not f[\"name\"] in remove_fields]\n",
    "\n",
    "    adds_dissolved = manage_data.dissolve_boundaries(adds_feature_collection, dissolve_fields=dissolve_fields)\n",
    "\n",
    "    print(\"Dissolve boundaries completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2431f",
   "metadata": {},
   "source": [
    "### Add new features to the Dashboard layer\n",
    "\n",
    "Finally, the aggregated rows and dissolved geometries are appended to the Dashboard layer via edit_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c16524",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adds:\n",
    "\n",
    "    # Convert feature collection to list of features,\n",
    "    # which is the required parameter type for edit_features method\n",
    "    adds_features = adds_dissolved.query().features\n",
    "    message = dashboard_layer.edit_features(adds_features)\n",
    "    added_list = message[\"addResults\"]\n",
    "\n",
    "    print(\"The following features were added successfully:\")\n",
    "    for a in added_list:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7d3f1",
   "metadata": {},
   "source": [
    "## Part III: Send email message using webhook\n",
    "\n",
    "Ideally I would accomplish this section simply using the send_notification method on the user in the py API; however I receive permissions errors. Someone with Esri confirmed my code to accomplish this worked for them; possible reason mine fails (only feasible reason? Only different variable?) is that my org is Personal Use License. 🤷 Webhook works fine.\n",
    "\n",
    "Webhook (url removed for GitHub) was created using [Make (formerly Integromat)](https://www.make.com/).\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aab01f",
   "metadata": {},
   "source": [
    "### Set up messages to send to webhook url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9744e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adds:\n",
    "    subject = \"Added new features: Triple-D Notebook\"\n",
    "    body = \"The Triple-D (Disaster Declarations Dashboard) ArcGIS Notebook ran successfully, and the following new features were found and added:<br><br>\"\n",
    "    attached = added_list\n",
    "\n",
    "else: \n",
    "    subject = \"No new features: Triple-D Notebook\"\n",
    "    body = \"The Triple-D (Disaster Declarations Dashboard) ArcGIS Notebook ran successfully, but no new features were found in the openFEMA Summaries to add.\"\n",
    "    attached = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b098396e",
   "metadata": {},
   "source": [
    "### Configure json and send to webhook endpoint URL\n",
    "Obviously this doesn't send anything if the script fails at any point before the post. May put in the extra work to ensure it sends an email in all cases, but for now this is good enough (after all, no email means the script failed just as surely as an email saying it failed).\n",
    "\n",
    "webhook_url in Notebook in AGOL with scheduled task includes webhook endpoint url; url removed in GitHub repo notebook for security."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\"subject\": subject, \"body\": body, \"attached\": attached}\n",
    "webhook_url = [\"insert webhook url\"]\n",
    "response = requests.post(webhook_url, json=payload)\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
