{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64d7fa5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc57611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayer\n",
    "from arcgis.features import manage_data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a73233",
   "metadata": {},
   "source": [
    "### Connecting to ArcGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4041c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login for the notebook running in AGOL\n",
    "#gis = GIS(\"home\")\n",
    "\n",
    "# Login for the notebook running in Pro locally...\n",
    "gis = GIS(\"pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c5b53",
   "metadata": {},
   "source": [
    "### Variables\n",
    "Currently the production layer (which is already powering the very very pretty Dashboard) is commented out and I'm grabbing a test layer instead (next block down). Will un-comment the operational layer when I'm 100% sure things aren't blowing up anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee2370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FeatureLayer url:\"https://services9.arcgis.com/GDVaV4SDJDDBT8gi/arcgis/rest/services/Disaster_Declarations_Summaries_v2/FeatureServer/1\">\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The Item ID of the service containing both the geometry layers and the dashboard layer\n",
    "# dd is \"Disaster Declarations\"\n",
    "dd_id = \"d37c3c2a6f1c4586baad82828bfc3c59\"\n",
    "\n",
    "# Get the item at this item ID\n",
    "dd_item = gis.content.get(dd_id)\n",
    "\n",
    "# Item ID 1 is the input layer used for getting geometries\n",
    "geometries_layer = dd_item.layers[1]\n",
    "\n",
    "print(geometries_layer)\n",
    "\n",
    "# Item ID 0 is the output layer displayed in the dashboard\n",
    "# COMMENTING OUT WHILE TESTING\n",
    "#dashboard_layer = dd_item.layers[0]\n",
    "\n",
    "#print(dashboard_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f835e84",
   "metadata": {},
   "source": [
    "### Get the Dashboard layer FOR TESTING ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707c59ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FeatureLayer url:\"https://services9.arcgis.com/GDVaV4SDJDDBT8gi/arcgis/rest/services/DisasterDeclarations_forTesting_2025only/FeatureServer/0\">\n"
     ]
    }
   ],
   "source": [
    "# ID of the item including Disaster Declarations Summaries subset FOR TESTING ONLY,\n",
    "# replaces \"dashboard_layer\" above through duration of testing\n",
    "test_id = \"edb716da51bc4f7882d13d425ad08fd2\"\n",
    "\n",
    "test_item = gis.content.get(test_id)\n",
    "\n",
    "dashboard_layer = test_item.layers[0]\n",
    "\n",
    "print(dashboard_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d93b45",
   "metadata": {},
   "source": [
    "### Connect to OpenFEMA API and get Disaster Declarations Summaries\n",
    "* Right right right; I forgot that the API by default only returns 1000 records. I shouldn't really NEED more records than that, since the script is going to be run once per day. One thousand records should be MORE than enough. But, I now realize I need to do a little footwork to make sure I am just getting the 1000 _most recent_ records...\n",
    "\n",
    "* Okay added a sort order to the api call to only get the most recent records by declarationDate! That should do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9d0bef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>femaDeclarationString</th>\n",
       "      <th>disasterNumber</th>\n",
       "      <th>state</th>\n",
       "      <th>declarationType</th>\n",
       "      <th>declarationDate</th>\n",
       "      <th>fyDeclared</th>\n",
       "      <th>incidentType</th>\n",
       "      <th>declarationTitle</th>\n",
       "      <th>ihProgramDeclared</th>\n",
       "      <th>iaProgramDeclared</th>\n",
       "      <th>...</th>\n",
       "      <th>placeCode</th>\n",
       "      <th>designatedArea</th>\n",
       "      <th>declarationRequestNumber</th>\n",
       "      <th>lastIAFilingDate</th>\n",
       "      <th>incidentId</th>\n",
       "      <th>region</th>\n",
       "      <th>designatedIncidentTypes</th>\n",
       "      <th>lastRefresh</th>\n",
       "      <th>hash</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FM-5612-CA</td>\n",
       "      <td>5612</td>\n",
       "      <td>CA</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-09-03T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>2-7 FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99009</td>\n",
       "      <td>Calaveras (County)</td>\n",
       "      <td>25121</td>\n",
       "      <td>None</td>\n",
       "      <td>2025090301</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-09-03T18:41:07.857Z</td>\n",
       "      <td>d017531813b75fc753371c26b246931d48de651e</td>\n",
       "      <td>28a1ba9f-d914-4024-9e75-4a66b5bba092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FM-5611-MT</td>\n",
       "      <td>5611</td>\n",
       "      <td>MT</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-26T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>WINDY ROCK FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99077</td>\n",
       "      <td>Powell (County)</td>\n",
       "      <td>25119</td>\n",
       "      <td>None</td>\n",
       "      <td>2025082701</td>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-28T18:01:23.160Z</td>\n",
       "      <td>29e175a73b969da6864182e703e3cb3f8d0bb32d</td>\n",
       "      <td>41329e57-2046-4196-a63d-902f3e7c923c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FM-5610-OR</td>\n",
       "      <td>5610</td>\n",
       "      <td>OR</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-23T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>FLAT FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99017</td>\n",
       "      <td>Deschutes (County)</td>\n",
       "      <td>25117</td>\n",
       "      <td>None</td>\n",
       "      <td>2025082301</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-25T18:21:58.453Z</td>\n",
       "      <td>c4a190d030807595da90813aabc6ad2175917668</td>\n",
       "      <td>df7cb24f-8e5a-4c1e-923e-4c75c9ec4581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FM-5610-OR</td>\n",
       "      <td>5610</td>\n",
       "      <td>OR</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-23T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>FLAT FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99031</td>\n",
       "      <td>Jefferson (County)</td>\n",
       "      <td>25117</td>\n",
       "      <td>None</td>\n",
       "      <td>2025082301</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-25T18:21:58.453Z</td>\n",
       "      <td>8b07b29243bdbba511790332bd3fa9cca0fe33fd</td>\n",
       "      <td>f0604c05-113b-449e-8e4a-f3b5076af546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FM-5609-HI</td>\n",
       "      <td>5609</td>\n",
       "      <td>HI</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-19T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>KUNIA ROAD FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99003</td>\n",
       "      <td>Honolulu (County)</td>\n",
       "      <td>25114</td>\n",
       "      <td>None</td>\n",
       "      <td>2025082001</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-21T18:22:16.374Z</td>\n",
       "      <td>731df26a647e5a0338177f445bab7a23b6f8d6ed</td>\n",
       "      <td>ffab7fa0-2e69-428d-b4d3-da95ca352c03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  femaDeclarationString  disasterNumber state declarationType  \\\n",
       "0            FM-5612-CA            5612    CA              FM   \n",
       "1            FM-5611-MT            5611    MT              FM   \n",
       "2            FM-5610-OR            5610    OR              FM   \n",
       "3            FM-5610-OR            5610    OR              FM   \n",
       "4            FM-5609-HI            5609    HI              FM   \n",
       "\n",
       "            declarationDate  fyDeclared incidentType declarationTitle  \\\n",
       "0  2025-09-03T00:00:00.000Z        2025         Fire         2-7 FIRE   \n",
       "1  2025-08-26T00:00:00.000Z        2025         Fire  WINDY ROCK FIRE   \n",
       "2  2025-08-23T00:00:00.000Z        2025         Fire       FLAT FIRE    \n",
       "3  2025-08-23T00:00:00.000Z        2025         Fire       FLAT FIRE    \n",
       "4  2025-08-19T00:00:00.000Z        2025         Fire  KUNIA ROAD FIRE   \n",
       "\n",
       "   ihProgramDeclared  iaProgramDeclared  ...  placeCode      designatedArea  \\\n",
       "0              False              False  ...      99009  Calaveras (County)   \n",
       "1              False              False  ...      99077     Powell (County)   \n",
       "2              False              False  ...      99017  Deschutes (County)   \n",
       "3              False              False  ...      99031  Jefferson (County)   \n",
       "4              False              False  ...      99003   Honolulu (County)   \n",
       "\n",
       "  declarationRequestNumber lastIAFilingDate  incidentId  region  \\\n",
       "0                    25121             None  2025090301       9   \n",
       "1                    25119             None  2025082701       8   \n",
       "2                    25117             None  2025082301      10   \n",
       "3                    25117             None  2025082301      10   \n",
       "4                    25114             None  2025082001       9   \n",
       "\n",
       "  designatedIncidentTypes               lastRefresh  \\\n",
       "0                       R  2025-09-03T18:41:07.857Z   \n",
       "1                       R  2025-08-28T18:01:23.160Z   \n",
       "2                       R  2025-08-25T18:21:58.453Z   \n",
       "3                       R  2025-08-25T18:21:58.453Z   \n",
       "4                       R  2025-08-21T18:22:16.374Z   \n",
       "\n",
       "                                       hash  \\\n",
       "0  d017531813b75fc753371c26b246931d48de651e   \n",
       "1  29e175a73b969da6864182e703e3cb3f8d0bb32d   \n",
       "2  c4a190d030807595da90813aabc6ad2175917668   \n",
       "3  8b07b29243bdbba511790332bd3fa9cca0fe33fd   \n",
       "4  731df26a647e5a0338177f445bab7a23b6f8d6ed   \n",
       "\n",
       "                                     id  \n",
       "0  28a1ba9f-d914-4024-9e75-4a66b5bba092  \n",
       "1  41329e57-2046-4196-a63d-902f3e7c923c  \n",
       "2  df7cb24f-8e5a-4c1e-923e-4c75c9ec4581  \n",
       "3  f0604c05-113b-449e-8e4a-f3b5076af546  \n",
       "4  ffab7fa0-2e69-428d-b4d3-da95ca352c03  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Within the API URL, filter the records to return only fyDeclared to 2013 or newer.\n",
    "# US Census GDBs only go back to 2013; before that it's shapefiles only\n",
    "# and I refuse to touch shapefiles, at least for the scope of this project.\n",
    "\n",
    "api_url = r\"https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries?$filter=fyDeclared ge 2013&$orderby=declarationDate desc\"\n",
    "\n",
    "# Plug in the URL and capture the response obj\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Convert response to JSON\n",
    "data = response.json()\n",
    "\n",
    "# Okay so after a little digging I really only need the following (leave out the metadata)\n",
    "summaries_df = pd.DataFrame(data[\"DisasterDeclarationsSummaries\"])\n",
    "\n",
    "summaries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5b798",
   "metadata": {},
   "source": [
    "### Convert pseudo-date columns to actual date columns\n",
    "I checked all the fips / code fields to ensure they're object / string type (I deleted that block while tidying up), so the offending fields remaining are the pseudo-date fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c9999ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = [\"declarationDate\", \"incidentBeginDate\", \"incidentEndDate\", \"disasterCloseoutDate\", \"lastIAFilingDate\", \"lastRefresh\"]\n",
    "\n",
    "for dc in date_columns:\n",
    "    summaries_df[dc] = pd.to_datetime(summaries_df[dc], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee860810",
   "metadata": {},
   "source": [
    "### Add full FIPS Code (counties) and full Tribal Code columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e31bd54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    06009\n",
      "1    30077\n",
      "2    41017\n",
      "3    41031\n",
      "4    15003\n",
      "Name: fipsFullCode, dtype: object\n",
      "0    0699009\n",
      "1    3099077\n",
      "2    4199017\n",
      "3    4199031\n",
      "4    1599003\n",
      "Name: fipsTribalCode, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Add to my df the fields I will need for comparison\n",
    "summaries_df[\"fipsFullCode\"] = summaries_df[\"fipsStateCode\"] + summaries_df[\"fipsCountyCode\"]\n",
    "summaries_df[\"fipsTribalCode\"] = summaries_df[\"fipsStateCode\"] + summaries_df[\"placeCode\"]\n",
    "\n",
    "print(summaries_df[\"fipsFullCode\"].head())\n",
    "print(summaries_df[\"fipsTribalCode\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5ff54",
   "metadata": {},
   "source": [
    "* Considering how I'm going to get the data from the API in shape for the comparison etc. I should just add the two additional columns I added manually for the dashboard I made first, COVID and Entity. After I add and calculate them, the comparisons will all be much easier, because I can just reference those fields for processing the data in chunks (i.e. step 1 process statewide, step 2 process counties, step 3 process tribal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44961960",
   "metadata": {},
   "source": [
    "### Add & calc \"COVID19\" field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f76cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good lord I can't remember how to calculate any of these fields with pandas... ðŸ¤£ðŸ˜­\n",
    "# Anyway the first one I need to calc is the COVID column, simple yes/no\n",
    "\n",
    "summaries_df[\"COVID19\"] = np.where(summaries_df[\"declarationTitle\"].str.contains(\"COVID-19\"), \"Show only COVID-19\", \"Show only non-COVID-19\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ea0ff",
   "metadata": {},
   "source": [
    "### Add & calc \"Entities\" field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8262e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For my next trick I'll use np.select instead of np.where since to code new Entity column\n",
    "# I have three possible values not just 2 / yes no / on off\n",
    "\n",
    "entity_conditions = [\n",
    "    summaries_df[\"designatedArea\"] == \"Statewide\",\n",
    "    (summaries_df[\"designatedArea\"] != \"Statewide\") & (summaries_df[\"fipsCountyCode\"] == \"000\"),\n",
    "    (summaries_df[\"designatedArea\"] != \"Statewide\") & (summaries_df[\"fipsCountyCode\"] != \"000\")\n",
    "]\n",
    "\n",
    "entity_values = [\"State or Equivalent\", \"Tribal Area or Equivalent\", \"County or Equivalent\"]\n",
    "\n",
    "summaries_df[\"Entity\"] = np.select(entity_conditions, entity_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f871d84d",
   "metadata": {},
   "source": [
    "### Groupby \"femaDeclarationString\", get temporal range (prelim analysis; to delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba40e248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze = summaries_df.groupby(\"femaDeclarationString\")[\"declarationDate\"].agg([\"min\", \"max\"])\n",
    "\n",
    "analyze[\"range\"] = (analyze[\"max\"] - analyze[\"min\"]).dt.total_seconds() / 3600\n",
    "\n",
    "analyze[\"range\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b838fb85",
   "metadata": {},
   "source": [
    "Well that's encouraging (no really I'm not even being sarcastic). I get a whole column of big fat zeros for the declaredDate ranges of all the fema Dec Strings. Honestly...that means I should be fine just proceeding with my simple it's-there-or-not check. I should probably also commit.\n",
    "\n",
    "OK getting near end-of-day. But now I know I can go forward with a comparison so maybe I'll start that part..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399d2d6",
   "metadata": {},
   "source": [
    "### Let's just re-do the bottom four blocks with a one-liner now that ChatGPT is helping jog my memory from DSTP XD\n",
    "Can you believe I forgot about isin?? And MERGE??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6929c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_sdf = dashboard_layer.query().sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e5b92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>femaDeclarationString</th>\n",
       "      <th>disasterNumber</th>\n",
       "      <th>state</th>\n",
       "      <th>declarationType</th>\n",
       "      <th>declarationDate</th>\n",
       "      <th>fyDeclared</th>\n",
       "      <th>incidentType</th>\n",
       "      <th>declarationTitle</th>\n",
       "      <th>ihProgramDeclared</th>\n",
       "      <th>iaProgramDeclared</th>\n",
       "      <th>...</th>\n",
       "      <th>incidentId</th>\n",
       "      <th>region</th>\n",
       "      <th>designatedIncidentTypes</th>\n",
       "      <th>lastRefresh</th>\n",
       "      <th>hash</th>\n",
       "      <th>id</th>\n",
       "      <th>fipsFullCode</th>\n",
       "      <th>fipsTribalCode</th>\n",
       "      <th>COVID19</th>\n",
       "      <th>Entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FM-5612-CA</td>\n",
       "      <td>5612</td>\n",
       "      <td>CA</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-09-03 00:00:00+00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>2-7 FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2025090301</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-09-03 18:41:07.857000+00:00</td>\n",
       "      <td>d017531813b75fc753371c26b246931d48de651e</td>\n",
       "      <td>28a1ba9f-d914-4024-9e75-4a66b5bba092</td>\n",
       "      <td>06009</td>\n",
       "      <td>0699009</td>\n",
       "      <td>Show only non-COVID-19</td>\n",
       "      <td>County or Equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FM-5611-MT</td>\n",
       "      <td>5611</td>\n",
       "      <td>MT</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-26 00:00:00+00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>WINDY ROCK FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2025082701</td>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-28 18:01:23.160000+00:00</td>\n",
       "      <td>29e175a73b969da6864182e703e3cb3f8d0bb32d</td>\n",
       "      <td>41329e57-2046-4196-a63d-902f3e7c923c</td>\n",
       "      <td>30077</td>\n",
       "      <td>3099077</td>\n",
       "      <td>Show only non-COVID-19</td>\n",
       "      <td>County or Equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FM-5610-OR</td>\n",
       "      <td>5610</td>\n",
       "      <td>OR</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-23 00:00:00+00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>FLAT FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2025082301</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-25 18:21:58.453000+00:00</td>\n",
       "      <td>c4a190d030807595da90813aabc6ad2175917668</td>\n",
       "      <td>df7cb24f-8e5a-4c1e-923e-4c75c9ec4581</td>\n",
       "      <td>41017</td>\n",
       "      <td>4199017</td>\n",
       "      <td>Show only non-COVID-19</td>\n",
       "      <td>County or Equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FM-5610-OR</td>\n",
       "      <td>5610</td>\n",
       "      <td>OR</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-23 00:00:00+00:00</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>FLAT FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>2025082301</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-25 18:21:58.453000+00:00</td>\n",
       "      <td>8b07b29243bdbba511790332bd3fa9cca0fe33fd</td>\n",
       "      <td>f0604c05-113b-449e-8e4a-f3b5076af546</td>\n",
       "      <td>41031</td>\n",
       "      <td>4199031</td>\n",
       "      <td>Show only non-COVID-19</td>\n",
       "      <td>County or Equivalent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  femaDeclarationString  disasterNumber state declarationType  \\\n",
       "0            FM-5612-CA            5612    CA              FM   \n",
       "1            FM-5611-MT            5611    MT              FM   \n",
       "2            FM-5610-OR            5610    OR              FM   \n",
       "3            FM-5610-OR            5610    OR              FM   \n",
       "\n",
       "            declarationDate  fyDeclared incidentType declarationTitle  \\\n",
       "0 2025-09-03 00:00:00+00:00        2025         Fire         2-7 FIRE   \n",
       "1 2025-08-26 00:00:00+00:00        2025         Fire  WINDY ROCK FIRE   \n",
       "2 2025-08-23 00:00:00+00:00        2025         Fire       FLAT FIRE    \n",
       "3 2025-08-23 00:00:00+00:00        2025         Fire       FLAT FIRE    \n",
       "\n",
       "   ihProgramDeclared  iaProgramDeclared  ...  incidentId  region  \\\n",
       "0              False              False  ...  2025090301       9   \n",
       "1              False              False  ...  2025082701       8   \n",
       "2              False              False  ...  2025082301      10   \n",
       "3              False              False  ...  2025082301      10   \n",
       "\n",
       "  designatedIncidentTypes                      lastRefresh  \\\n",
       "0                       R 2025-09-03 18:41:07.857000+00:00   \n",
       "1                       R 2025-08-28 18:01:23.160000+00:00   \n",
       "2                       R 2025-08-25 18:21:58.453000+00:00   \n",
       "3                       R 2025-08-25 18:21:58.453000+00:00   \n",
       "\n",
       "                                       hash  \\\n",
       "0  d017531813b75fc753371c26b246931d48de651e   \n",
       "1  29e175a73b969da6864182e703e3cb3f8d0bb32d   \n",
       "2  c4a190d030807595da90813aabc6ad2175917668   \n",
       "3  8b07b29243bdbba511790332bd3fa9cca0fe33fd   \n",
       "\n",
       "                                     id fipsFullCode fipsTribalCode  \\\n",
       "0  28a1ba9f-d914-4024-9e75-4a66b5bba092        06009        0699009   \n",
       "1  41329e57-2046-4196-a63d-902f3e7c923c        30077        3099077   \n",
       "2  df7cb24f-8e5a-4c1e-923e-4c75c9ec4581        41017        4199017   \n",
       "3  f0604c05-113b-449e-8e4a-f3b5076af546        41031        4199031   \n",
       "\n",
       "                  COVID19                Entity  \n",
       "0  Show only non-COVID-19  County or Equivalent  \n",
       "1  Show only non-COVID-19  County or Equivalent  \n",
       "2  Show only non-COVID-19  County or Equivalent  \n",
       "3  Show only non-COVID-19  County or Equivalent  \n",
       "\n",
       "[4 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adds_df = summaries_df[~summaries_df[\"femaDeclarationString\"].isin(dashboard_sdf[\"femaDeclarationString\"])]\n",
    "\n",
    "adds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c2247",
   "metadata": {},
   "source": [
    "### Good Morning 9/5\n",
    "I don't think it's tricky that tribal and county original Summary observations with the same Dec string are treated separately. We'll (I'm pretty sure?) be processing all three entity types separately anyway, so there won't be a need to make e.g. a multi-column key or any shenanigans like that.\n",
    "\n",
    "What do we want to accomplish this fine Friday?\n",
    "* I need to remove the fields I don't need from the adds_df and then drop dups, effectively dissolving that dataframe.\n",
    "* I guess somewhere along the way I ought to convert it to a spatial data frame; will probably make adding the rows to the dashboard layer easier.\n",
    "* BEFORE I do any of the above, I need to use the appropriate field (depending on entity) and grab the correct geometries to dissolve for that Dec string.\n",
    "* Actually I guess I don't need to do it before; I can do it after; I already have the dfs I need to work with. But procedurally it should happen before.\n",
    "* What data structure for that? I mean...dict with Dec string as key and list of geom objects as values? What's not to love about that? Gives me warm fuzzies just thinking about it.\n",
    "\n",
    "If we got even a fraction of the above done today I'd be happy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f5e2b4",
   "metadata": {},
   "source": [
    "### Build dict of primary/foreign keys\n",
    "Okay now that I have a little more of the script fleshed out, tidying this up and re-doing a few comments here. Main thing I have to remember for further down the script is that THE KEYS ARE THE FIELDS IN THE GEOMETRIES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "304d81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe I will need three different queries for my geometries layer\n",
    "# I'll need to query to get state geometries, county geometries and tribal area geometries:\n",
    "\n",
    "# Get the states on this field:\n",
    "# (States we'll check first; )\n",
    "state_field = \"State_FIPS\"\n",
    "\n",
    "# Get the counties on this field:\n",
    "county_field = \"Full_FIPS\"\n",
    "\n",
    "# Crappily, in assembling the original dashboard layer I realized that\n",
    "# the Declaration data may match ANY ONE of these tribal fields, so I need to check all three:\n",
    "tribal_field1 = \"AIANNHFP1\"\n",
    "tribal_field2 = \"AIANNHFP2\"\n",
    "tribal_field3 = \"AIANNHFP3\"\n",
    "\n",
    "# Just updated the values below to reflect the fields I've added to the Summaries df; they should be GTG now\n",
    "key_fields_dict = {\n",
    "    \"State_FIPS\": \"fipsStateCode\",\n",
    "    \"Full_FIPS\": \"fipsFullCode\",\n",
    "    \"AIANNHFP1\": \"fipsTribalCode\",\n",
    "    \"AIANNHFP2\": \"fipsTribalCode\", # No idea why there are three of these...or why the Summaries sometimes use 2 and 3...\n",
    "    \"AIANNHFP3\": \"fipsTribalCode\" # What a pain in the @$$...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a493b8",
   "metadata": {},
   "source": [
    "### Get geometries associated with each Dec string for all three entity types\n",
    "Since this has to be done technically 5 times (there are three different keys for Tribal), a function it is\n",
    "(Yeah we'll throw everything in a function later, probably, since it's just tidy, but this requires it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d433335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a spatial dataframe from the geometries layer\n",
    "# I really only need the \n",
    "geometries_sdf = geometries_layer.query().sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c85969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [femaDeclarationString, disasterNumber, state, declarationType, declarationDate, fyDeclared, incidentType, declarationTitle, ihProgramDeclared, iaProgramDeclared, paProgramDeclared, hmProgramDeclared, incidentBeginDate, incidentEndDate, disasterCloseoutDate, tribalRequest, fipsStateCode, fipsCountyCode, placeCode, designatedArea, declarationRequestNumber, lastIAFilingDate, incidentId, region, designatedIncidentTypes, lastRefresh, hash, id, fipsFullCode, fipsTribalCode, COVID19, Entity, OBJECTID, Entity_2, Full_FIPS, County_FIPS, County_Name, State_FIPS, State_Name, State_Abbreviation, Tribal_FIPS, Tribal_Basename, Tribal_Name, AIANNHFP1, AIANNHFP2, AIANNHFP3, AIANNHNS, Census_Year, Shape__Area, Shape__Length, SHAPE]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 51 columns]\n",
      "  femaDeclarationString  disasterNumber state declarationType  \\\n",
      "0            FM-5612-CA            5612    CA              FM   \n",
      "1            FM-5611-MT            5611    MT              FM   \n",
      "2            FM-5610-OR            5610    OR              FM   \n",
      "3            FM-5610-OR            5610    OR              FM   \n",
      "\n",
      "            declarationDate  fyDeclared incidentType declarationTitle  \\\n",
      "0 2025-09-03 00:00:00+00:00        2025         Fire         2-7 FIRE   \n",
      "1 2025-08-26 00:00:00+00:00        2025         Fire  WINDY ROCK FIRE   \n",
      "2 2025-08-23 00:00:00+00:00        2025         Fire       FLAT FIRE    \n",
      "3 2025-08-23 00:00:00+00:00        2025         Fire       FLAT FIRE    \n",
      "\n",
      "   ihProgramDeclared  iaProgramDeclared  ...  Tribal_Basename  Tribal_Name  \\\n",
      "0              False              False  ...             <NA>         <NA>   \n",
      "1              False              False  ...             <NA>         <NA>   \n",
      "2              False              False  ...             <NA>         <NA>   \n",
      "3              False              False  ...             <NA>         <NA>   \n",
      "\n",
      "  AIANNHFP1 AIANNHFP2 AIANNHFP3  AIANNHNS Census_Year         Shape__Area  \\\n",
      "0      <NA>      <NA>      <NA>      <NA>        2025   4347170942.960938   \n",
      "1      <NA>      <NA>      <NA>      <NA>        2025  12916839477.203125   \n",
      "2      <NA>      <NA>      <NA>      <NA>        2025  15241972379.453125   \n",
      "3      <NA>      <NA>      <NA>      <NA>        2025   9164136488.898438   \n",
      "\n",
      "   Shape__Length                                              SHAPE  \n",
      "0  319087.863892  {\"rings\": [[[-13427073.7835, 4630770.9105], [-...  \n",
      "1  671747.744721  {\"rings\": [[[-12631038.7077, 6037032.6359], [-...  \n",
      "2  706417.816816  {\"rings\": [[[-13481100.5781, 5486843.1441], [-...  \n",
      "3  466107.542188  {\"rings\": [[[-13513910.2275, 5526480.1649], [-...  \n",
      "\n",
      "[4 rows x 51 columns]\n",
      "Empty DataFrame\n",
      "Columns: [femaDeclarationString, disasterNumber, state, declarationType, declarationDate, fyDeclared, incidentType, declarationTitle, ihProgramDeclared, iaProgramDeclared, paProgramDeclared, hmProgramDeclared, incidentBeginDate, incidentEndDate, disasterCloseoutDate, tribalRequest, fipsStateCode, fipsCountyCode, placeCode, designatedArea, declarationRequestNumber, lastIAFilingDate, incidentId, region, designatedIncidentTypes, lastRefresh, hash, id, fipsFullCode, fipsTribalCode, COVID19, Entity, OBJECTID, Entity_2, Full_FIPS, County_FIPS, County_Name, State_FIPS, State_Name, State_Abbreviation, Tribal_FIPS, Tribal_Basename, Tribal_Name, AIANNHFP1, AIANNHFP2, AIANNHFP3, AIANNHNS, Census_Year, Shape__Area, Shape__Length, SHAPE]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 51 columns]\n",
      "Empty DataFrame\n",
      "Columns: [femaDeclarationString, disasterNumber, state, declarationType, declarationDate, fyDeclared, incidentType, declarationTitle, ihProgramDeclared, iaProgramDeclared, paProgramDeclared, hmProgramDeclared, incidentBeginDate, incidentEndDate, disasterCloseoutDate, tribalRequest, fipsStateCode, fipsCountyCode, placeCode, designatedArea, declarationRequestNumber, lastIAFilingDate, incidentId, region, designatedIncidentTypes, lastRefresh, hash, id, fipsFullCode, fipsTribalCode, COVID19, Entity, OBJECTID, Entity_2, Full_FIPS, County_FIPS, County_Name, State_FIPS, State_Name, State_Abbreviation, Tribal_FIPS, Tribal_Basename, Tribal_Name, AIANNHFP1, AIANNHFP2, AIANNHFP3, AIANNHNS, Census_Year, Shape__Area, Shape__Length, SHAPE]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 51 columns]\n",
      "Empty DataFrame\n",
      "Columns: [femaDeclarationString, disasterNumber, state, declarationType, declarationDate, fyDeclared, incidentType, declarationTitle, ihProgramDeclared, iaProgramDeclared, paProgramDeclared, hmProgramDeclared, incidentBeginDate, incidentEndDate, disasterCloseoutDate, tribalRequest, fipsStateCode, fipsCountyCode, placeCode, designatedArea, declarationRequestNumber, lastIAFilingDate, incidentId, region, designatedIncidentTypes, lastRefresh, hash, id, fipsFullCode, fipsTribalCode, COVID19, Entity, OBJECTID, Entity_2, Full_FIPS, County_FIPS, County_Name, State_FIPS, State_Name, State_Abbreviation, Tribal_FIPS, Tribal_Basename, Tribal_Name, AIANNHFP1, AIANNHFP2, AIANNHFP3, AIANNHNS, Census_Year, Shape__Area, Shape__Length, SHAPE]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "state = \"State or Equivalent\"\n",
    "county = \"County or Equivalent\"\n",
    "tribal = \"Tribal or Equivalent\" \n",
    "\n",
    "def get_geometries(entity, field):\n",
    "\n",
    "    # For the loop I want to make sure I'm only looking at the adds\n",
    "    # that correspond to the entity level I'm interested in here\n",
    "    entity_adds_df = adds_df[adds_df[\"Entity\"] == entity]\n",
    "\n",
    "    # NEED to specify an empty string for at least one of the suffixes here;\n",
    "    # Otherwise I have no \"Entity\" field and my Dashboard layer and adds feature collection won't have matching fields\n",
    "    merged = entity_adds_df.merge(geometries_sdf, left_on=[key_fields_dict[field]], right_on=field, suffixes=('', '_2'))\n",
    "\n",
    "    print(merged.head())\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "state_geometries = get_geometries(state, state_field)\n",
    "\n",
    "county_geometries = get_geometries(county, county_field)\n",
    "\n",
    "tribal1_geometries = get_geometries(tribal, tribal_field1)\n",
    "\n",
    "tribal2_geometries = get_geometries(tribal, tribal_field2)\n",
    "\n",
    "tribal3_geometries = get_geometries(tribal, tribal_field3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baaa323",
   "metadata": {},
   "source": [
    "### Coffee Break 9/5\n",
    "\n",
    "Dang ChatGPT does make coding that much faster. Not like a person isn't looking up syntax either way...but without Chat you need to wade through _close but not quite_ pages from StackOverflow etc....with Chat you can describe exactly what you're trying to do and not have to piece together info from 5 different examples that took you an hour to assemble.\n",
    "\n",
    "Okay, well, despite a super-slow start and being super-frustrated and possibly having early onset of dementia, we finished what we set out to do this morning. What's next?\n",
    "\n",
    "* Dissolve the geometries...I'll look into that now\n",
    "* For later: smash the final geometry layer for each Dec string into the Summaries df (or a derivative of the Summaries df)\n",
    "\n",
    "You know...back up...I probably don't want my data above in the format I put it in. I probably don't want a dict and the value as a list of strings. I probably want the original un-smashed version. That's what dissolve_boundaries is going to want, I'll bet...okay okay, lemme commit before I start making changes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c71c579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FeatureCollection>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties_add_fcol = county_geometries.spatial.to_feature_collection()\n",
    "\n",
    "counties_add_fcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "335281f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Entity', 'femaDeclarationString', 'disasterNumber', 'state', 'declarationType', 'declarationDate', 'fyDeclared', 'incidentType', 'declarationTitle', 'incidentBeginDate', 'incidentEndDate', 'disasterCloseoutDate', 'tribalRequest', 'fipsStateCode', 'declarationRequestNumber', 'lastIAFilingDate', 'incidentId', 'region', 'designatedIncidentTypes', 'COVID19']\n"
     ]
    }
   ],
   "source": [
    "remove_fields = [\"OBJECTID\", \"Shape__Area\", \"Shape__Length\", \"SHAPE\"]\n",
    "\n",
    "dissolve_fields = [f[\"name\"] for f in dashboard_layer.properties.fields if not f[\"name\"] in remove_fields]\n",
    "\n",
    "print(dissolve_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d07894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['femaDeclarationString',\n",
       " 'disasterNumber',\n",
       " 'state',\n",
       " 'declarationType',\n",
       " 'declarationDate',\n",
       " 'fyDeclared',\n",
       " 'incidentType',\n",
       " 'declarationTitle',\n",
       " 'ihProgramDeclared',\n",
       " 'iaProgramDeclared',\n",
       " 'paProgramDeclared',\n",
       " 'hmProgramDeclared',\n",
       " 'incidentBeginDate',\n",
       " 'incidentEndDate',\n",
       " 'disasterCloseoutDate',\n",
       " 'tribalRequest',\n",
       " 'fipsStateCode',\n",
       " 'fipsCountyCode',\n",
       " 'placeCode',\n",
       " 'designatedArea',\n",
       " 'declarationRequestNumber',\n",
       " 'lastIAFilingDate',\n",
       " 'incidentId',\n",
       " 'region',\n",
       " 'designatedIncidentTypes',\n",
       " 'lastRefresh',\n",
       " 'hash',\n",
       " 'id',\n",
       " 'fipsFullCode',\n",
       " 'fipsTribalCode',\n",
       " 'COVID19',\n",
       " 'Entity',\n",
       " 'OBJECTID',\n",
       " 'Entity_2',\n",
       " 'Full_FIPS',\n",
       " 'County_FIPS',\n",
       " 'County_Name',\n",
       " 'State_FIPS',\n",
       " 'State_Name',\n",
       " 'State_Abbreviation',\n",
       " 'Tribal_FIPS',\n",
       " 'Tribal_Basename',\n",
       " 'Tribal_Name',\n",
       " 'AIANNHFP1',\n",
       " 'AIANNHFP2',\n",
       " 'AIANNHFP3',\n",
       " 'AIANNHNS',\n",
       " 'Census_Year',\n",
       " 'Shape__Area',\n",
       " 'Shape__Length',\n",
       " 'SHAPE']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_dissolve_fields = county_geometries.columns.to_list()\n",
    "\n",
    "check_dissolve_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c863f",
   "metadata": {},
   "source": [
    "Ah hah! Okay that's why my dissolve on all the fields is failing...in my adds, because of the merge, I have and Entity_x and Entity_y. But no Entity.\n",
    "\n",
    "Soooo I'm pretty sure I can specify the names of those fields right? I remember doing that in DSTP...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00632010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "what_am_i_missing = [n for n in dissolve_fields if not n in check_dissolve_fields]\n",
    "\n",
    "what_am_i_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ebaa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"cost\": 0.004}\n"
     ]
    }
   ],
   "source": [
    "counties_add_dissolve = manage_data.dissolve_boundaries(counties_add_fcol, dissolve_fields=dissolve_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "373d4d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"item_container\" style=\"height: auto; overflow: hidden; border: 1px solid #cfcfcf; border-radius: 2px; background: #f6fafa; line-height: 1.21429em; padding: 10px;\">\n",
       "                    <div class=\"item_left\" style=\"width: 210px; float: left;\">\n",
       "                       <a href='https://www.arcgis.com//home/item.html?id=0a3a028edab74f799796cb90ce6f59e2' target='_blank'>\n",
       "                        <img src='http://static.arcgis.com/images/desktopapp.png' class=\"itemThumbnail\">\n",
       "                       </a>\n",
       "                    </div>\n",
       "\n",
       "                    <div class=\"item_right\"     style=\"float: none; width: auto; overflow: hidden;\">\n",
       "                        <a href='https://www.arcgis.com//home/item.html?id=0a3a028edab74f799796cb90ce6f59e2' target='_blank'><b>352860df8cb243daa705986c2363ded6</b>\n",
       "                        </a>\n",
       "                        <br/><br/><img src='https://www.arcgis.com//home/js/jsapi/esri/css/images/item_type_icons/featureshosted16.png' style=\"vertical-align:middle;\" width=16 height=16>Feature Layer Collection by AlderMaps\n",
       "                        <br/>Last Modified: September 05, 2025\n",
       "                        <br/>0 comments, 0 views\n",
       "                    </div>\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<Item title:\"352860df8cb243daa705986c2363ded6\" type:Feature Layer Collection owner:AlderMaps>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties_add_dissolve.query().sdf.spatial.to_featurelayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3355c",
   "metadata": {},
   "source": [
    "### Where we are\n",
    "Holy shit! Sorry there will be no apologetic polite asterisk-swapping in that expletive!\n",
    "\n",
    "Like literally we are nearlly finished with the whole workflow. THE WHOLE WORKFLOW.\n",
    "\n",
    "What's left to do:\n",
    "* Soooo I only supplied a single field for the dissolve field and forgot of course that it kicks out all the others. Need to get my list of fields to keep from the preexisting Dashboard layer and ram them in the parameters.\n",
    "* Then we just need to convert the dissolve layer to the correct data type...honestly isn't a feature collection OK for updating a layer? I don't recall but _that's_ certainly not a very big deal. Don't need ChatGPT for that.\n",
    "* Then we literally just need to do the updates. Feed it in, bam, done.\n",
    "* Then of course lots of cleaning up, more testing, more cleaning up, refactoring, more testing, more refactoring, maybe even some error handling LOL...\n",
    "\n",
    "...and that's it. Woooooooooooot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4cf43",
   "metadata": {},
   "source": [
    "### COB 9/5\n",
    "Okay took care of the first bullet above and got the dissolve working. Specifically smoothed out a hiccup where by list of dissolve fields derived from the Dashboard layer itself wasn't working because my adds df, after the merge, had an Entity_x and Entity_y field but no Entity. Easy fix.\n",
    "\n",
    "Now I can see a potential GOTCHA moment coming up next week. I confirmed that the field NAMES are all the same between both the Dashboard layer and the adds feature collection. But I don't know if the SCHEMAS match enough. I'm not sure if it's as picky as Append...where the schemas have to match perfectly...like, to update a feature layer and shove in my dict of edits, can I ram a short into a long? A long into a float? No idea. But it's something to be aware of next week if my updates fail.\n",
    "\n",
    "BUT I'M NOT THINKING ABOUT THAT NOW. We did enough this week and my brain is addled plenty. But I think we should a good solid working version of this by end of next week."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
