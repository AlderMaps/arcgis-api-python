{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e64d7fa5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc57611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from arcgis.gis import GIS\n",
    "from arcgis.features import FeatureLayer\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4041c933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login for the notebook running in AGOL\n",
    "#gis = GIS(\"home\")\n",
    "\n",
    "# Login for the notebook running in Pro locally...\n",
    "gis = GIS(\"pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c5b53",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee2370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FeatureLayer url:\"https://services9.arcgis.com/GDVaV4SDJDDBT8gi/arcgis/rest/services/Disaster_Declarations_Summaries_v2/FeatureServer/0\">\n",
      "<FeatureLayer url:\"https://services9.arcgis.com/GDVaV4SDJDDBT8gi/arcgis/rest/services/Disaster_Declarations_Summaries_v2/FeatureServer/1\">\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The Item ID of the service containing both the geometry layers and the dashboard layer\n",
    "# dd is \"Disaster Declarations\"\n",
    "dd_id = \"d37c3c2a6f1c4586baad82828bfc3c59\"\n",
    "\n",
    "# Get the item at this item ID\n",
    "dd_item = gis.content.get(dd_id)\n",
    "\n",
    "# Item ID 0 is the output layer displayed in the dashboard\n",
    "dashboard_layer = dd_item.layers[0]\n",
    "\n",
    "# Item ID 1 is the input layer used for getting geometries\n",
    "geometries_layer = dd_item.layers[1]\n",
    "\n",
    "print(dashboard_layer)\n",
    "\n",
    "print(geometries_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f638e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm thinking I'll need a little dict of the various fields I'll need to compare\n",
    "# for querying the geometries layer...?\n",
    "# The key is the field name in the FEMA data;\n",
    "# the value is the corresponding field in my geometries layer...\n",
    "# ACTUALLY I need to do that backwards because placeCODE would create duplicate keys...\n",
    "# SO the key will be in the geometries; the value will be the FEMA data\n",
    "\n",
    "compare_dict = {\n",
    "    \"State_FIPS\": \"fipsStateCode\", # This will only be checked where region == \"Statewide\"\n",
    "    \"Full_FIPS\": \"fipsCountyCode\", # Will have to check the type of this before comparison!\n",
    "    \"AIANNHFP1\": \"placeCode\", # For these last three we will need to construct the full AIA..., fipsStateCode + placeCode\n",
    "    \"AIANNHFP2\": \"placeCode\", # No idea why there are three of these...or why the Summaries sometimes use 2 and 3...\n",
    "    \"AIANNHFP3\": \"placeCode\" # What a pain in the @$$...\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d21ea439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I believe I will need three different queries for my geometries layer\n",
    "# I'll need to query to get state geometries, county geometries and tribal area geometries:\n",
    "\n",
    "# Get the states on this field:\n",
    "# (States we'll check first; )\n",
    "state_field = \"State_FIPS\"\n",
    "\n",
    "# Get the counties on this field:\n",
    "county_field = \"Full_FIPS\"\n",
    "\n",
    "# Crappily, in assembling the original dashboard layer I realized that\n",
    "# the Declaration data may match ANY ONE of these tribal fields, so I need to check all three:\n",
    "tribal_field1 = \"AIANNHFP1\"\n",
    "tribal_field2 = \"AIANNHFP2\"\n",
    "tribal_field3 = \"AIANNHFP3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d93b45",
   "metadata": {},
   "source": [
    "### EVERYTHING BELOW HERE IS FOR THE API..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d0bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within the API URL, filter the records to return only fyDeclared to 2013 or newer.\n",
    "# US Census GDBs only go back to 2013; before that it's shapefiles only\n",
    "# and I refuse to touch shapefiles, at least for the scope of this project.\n",
    "\n",
    "# Hahaha whoops, forgot that the api only returns 1000 records by default...\n",
    "# sooooo, had to add orderby desc to get the most recent by declarationDate\n",
    "# 98% sure this is the correct field to sort by; it should really be the field\n",
    "# by which records are entered into the db?...\n",
    "api_url = r\"https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries?$filter=fyDeclared ge 2013&$orderby=declarationDate desc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6c6e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plug in the URL and capture the response obj\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Convert response to JSON\n",
    "data = response.json()\n",
    "\n",
    "# Inspect what I got\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c927ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data.items():\n",
    "    print(f\"{k}, {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b809e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay so after a little digging I really only need the following (leave out the metadata)\n",
    "summaries_df = pd.DataFrame(data[\"DisasterDeclarationsSummaries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a9954d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025]\n"
     ]
    }
   ],
   "source": [
    "# Check my years\n",
    "print(summaries_df[\"fyDeclared\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "624e83c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>femaDeclarationString</th>\n",
       "      <th>disasterNumber</th>\n",
       "      <th>state</th>\n",
       "      <th>declarationType</th>\n",
       "      <th>declarationDate</th>\n",
       "      <th>fyDeclared</th>\n",
       "      <th>incidentType</th>\n",
       "      <th>declarationTitle</th>\n",
       "      <th>ihProgramDeclared</th>\n",
       "      <th>iaProgramDeclared</th>\n",
       "      <th>...</th>\n",
       "      <th>placeCode</th>\n",
       "      <th>designatedArea</th>\n",
       "      <th>declarationRequestNumber</th>\n",
       "      <th>lastIAFilingDate</th>\n",
       "      <th>incidentId</th>\n",
       "      <th>region</th>\n",
       "      <th>designatedIncidentTypes</th>\n",
       "      <th>lastRefresh</th>\n",
       "      <th>hash</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FM-5612-CA</td>\n",
       "      <td>5612</td>\n",
       "      <td>CA</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-09-03T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>2-7 FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99009</td>\n",
       "      <td>Calaveras (County)</td>\n",
       "      <td>25121</td>\n",
       "      <td>None</td>\n",
       "      <td>2025090301</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-09-03T18:41:07.857Z</td>\n",
       "      <td>d017531813b75fc753371c26b246931d48de651e</td>\n",
       "      <td>28a1ba9f-d914-4024-9e75-4a66b5bba092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FM-5611-MT</td>\n",
       "      <td>5611</td>\n",
       "      <td>MT</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-26T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>WINDY ROCK FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99077</td>\n",
       "      <td>Powell (County)</td>\n",
       "      <td>25119</td>\n",
       "      <td>None</td>\n",
       "      <td>2025082701</td>\n",
       "      <td>8</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-28T18:01:23.160Z</td>\n",
       "      <td>29e175a73b969da6864182e703e3cb3f8d0bb32d</td>\n",
       "      <td>41329e57-2046-4196-a63d-902f3e7c923c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FM-5610-OR</td>\n",
       "      <td>5610</td>\n",
       "      <td>OR</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-23T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>FLAT FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99031</td>\n",
       "      <td>Jefferson (County)</td>\n",
       "      <td>25117</td>\n",
       "      <td>None</td>\n",
       "      <td>2025082301</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-25T18:21:58.453Z</td>\n",
       "      <td>8b07b29243bdbba511790332bd3fa9cca0fe33fd</td>\n",
       "      <td>f0604c05-113b-449e-8e4a-f3b5076af546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FM-5610-OR</td>\n",
       "      <td>5610</td>\n",
       "      <td>OR</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-23T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>FLAT FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99017</td>\n",
       "      <td>Deschutes (County)</td>\n",
       "      <td>25117</td>\n",
       "      <td>None</td>\n",
       "      <td>2025082301</td>\n",
       "      <td>10</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-25T18:21:58.453Z</td>\n",
       "      <td>c4a190d030807595da90813aabc6ad2175917668</td>\n",
       "      <td>df7cb24f-8e5a-4c1e-923e-4c75c9ec4581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FM-5609-HI</td>\n",
       "      <td>5609</td>\n",
       "      <td>HI</td>\n",
       "      <td>FM</td>\n",
       "      <td>2025-08-19T00:00:00.000Z</td>\n",
       "      <td>2025</td>\n",
       "      <td>Fire</td>\n",
       "      <td>KUNIA ROAD FIRE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>99003</td>\n",
       "      <td>Honolulu (County)</td>\n",
       "      <td>25114</td>\n",
       "      <td>None</td>\n",
       "      <td>2025082001</td>\n",
       "      <td>9</td>\n",
       "      <td>R</td>\n",
       "      <td>2025-08-21T18:22:16.374Z</td>\n",
       "      <td>731df26a647e5a0338177f445bab7a23b6f8d6ed</td>\n",
       "      <td>ffab7fa0-2e69-428d-b4d3-da95ca352c03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  femaDeclarationString  disasterNumber state declarationType  \\\n",
       "0            FM-5612-CA            5612    CA              FM   \n",
       "1            FM-5611-MT            5611    MT              FM   \n",
       "2            FM-5610-OR            5610    OR              FM   \n",
       "3            FM-5610-OR            5610    OR              FM   \n",
       "4            FM-5609-HI            5609    HI              FM   \n",
       "\n",
       "            declarationDate  fyDeclared incidentType declarationTitle  \\\n",
       "0  2025-09-03T00:00:00.000Z        2025         Fire         2-7 FIRE   \n",
       "1  2025-08-26T00:00:00.000Z        2025         Fire  WINDY ROCK FIRE   \n",
       "2  2025-08-23T00:00:00.000Z        2025         Fire       FLAT FIRE    \n",
       "3  2025-08-23T00:00:00.000Z        2025         Fire       FLAT FIRE    \n",
       "4  2025-08-19T00:00:00.000Z        2025         Fire  KUNIA ROAD FIRE   \n",
       "\n",
       "   ihProgramDeclared  iaProgramDeclared  ...  placeCode      designatedArea  \\\n",
       "0              False              False  ...      99009  Calaveras (County)   \n",
       "1              False              False  ...      99077     Powell (County)   \n",
       "2              False              False  ...      99031  Jefferson (County)   \n",
       "3              False              False  ...      99017  Deschutes (County)   \n",
       "4              False              False  ...      99003   Honolulu (County)   \n",
       "\n",
       "  declarationRequestNumber lastIAFilingDate  incidentId  region  \\\n",
       "0                    25121             None  2025090301       9   \n",
       "1                    25119             None  2025082701       8   \n",
       "2                    25117             None  2025082301      10   \n",
       "3                    25117             None  2025082301      10   \n",
       "4                    25114             None  2025082001       9   \n",
       "\n",
       "  designatedIncidentTypes               lastRefresh  \\\n",
       "0                       R  2025-09-03T18:41:07.857Z   \n",
       "1                       R  2025-08-28T18:01:23.160Z   \n",
       "2                       R  2025-08-25T18:21:58.453Z   \n",
       "3                       R  2025-08-25T18:21:58.453Z   \n",
       "4                       R  2025-08-21T18:22:16.374Z   \n",
       "\n",
       "                                       hash  \\\n",
       "0  d017531813b75fc753371c26b246931d48de651e   \n",
       "1  29e175a73b969da6864182e703e3cb3f8d0bb32d   \n",
       "2  8b07b29243bdbba511790332bd3fa9cca0fe33fd   \n",
       "3  c4a190d030807595da90813aabc6ad2175917668   \n",
       "4  731df26a647e5a0338177f445bab7a23b6f8d6ed   \n",
       "\n",
       "                                     id  \n",
       "0  28a1ba9f-d914-4024-9e75-4a66b5bba092  \n",
       "1  41329e57-2046-4196-a63d-902f3e7c923c  \n",
       "2  f0604c05-113b-449e-8e4a-f3b5076af546  \n",
       "3  df7cb24f-8e5a-4c1e-923e-4c75c9ec4581  \n",
       "4  ffab7fa0-2e69-428d-b4d3-da95ca352c03  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf5ab21",
   "metadata": {},
   "source": [
    "### Okay yeah it's a mess in here right now. Early development stages. Pardon the dust.\n",
    "Need to figure out exactly how this whole thing is going to work...\n",
    "...below begin the algorithms..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3339283",
   "metadata": {},
   "source": [
    "### Things that will have to be done, in no particular order:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851807e1",
   "metadata": {},
   "source": [
    "* BEFORE I dissolve (or the pd equivalent of dissolve) the summaries to the FEMA Declaration String level, I need to get all the counties / tribal areas associated with that string so I can grab their geometries and actually perform the spatial dissolve on them\n",
    "* Tricky with the above: If the FEMA Declaration String applies to both counties and tribal areas, these are treated separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86757b9",
   "metadata": {},
   "source": [
    "* Once I have the list of entities the FEMA Declaration String is for, grab the geometries for those counties and perform the dissolve on them. That new dissolve geometry will be the geometry applied to the new row written to the output Summaries dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890317e",
   "metadata": {},
   "source": [
    "* THEN dissolve (pd equivalent) the actual summaries, ensuring the schema matches that of the target Summaries dataset...tack on the geometry, apply edits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec6917",
   "metadata": {},
   "source": [
    "* Other tricky bits: Obviously we need to check if a given FEMA string already exists within the summaries dataset. I will need to check whether this is as straightforward as it sounds, or whether...hm. I will have to check whether the potential exists for Summary rows with the same FEMA String to be issued across multiple days...e.g., this string for these three counties is issued this day; then another three rows for an additional three counties are added UNDER THE SAME STRING...this will complicate the checking process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c274e99",
   "metadata": {},
   "source": [
    "* Yet more tricky bits: The fields from the summaries used to match the data to the appropriate geometries _is different depending on the level of the entity being matched_. \n",
    "\n",
    "For example, Statewide declarations will match on state fips, of course. Counties will match on a combination of state + county code (I could calc that field in the df before I begin...?), and tribal entities will match on...wtf will they match on again...I believe it's a concat of the state FIPS and placeCode...yes because the long tribal codes in the geometries are seven chars...I think. 🥴\n",
    "\n",
    "I could have just gone easy on myself and committed to representing only county-based declaration rows in my map. But does that simplicity accurately reflect the real world? NO. Does it create a more impressive script? NO! Does it get me a job faster? NO!! 😤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3553fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# Some code that will have to happen related to the above bullet:\n",
    "\n",
    "# Check the types of some important fields...if they came in as strings\n",
    "# then I don't need to covert them; otherwise I do...come on, big money no whammies!!\n",
    "print(summaries_df[\"fipsStateCode\"].dtype)\n",
    "print(summaries_df[\"fipsCountyCode\"].dtype)\n",
    "print(summaries_df[\"placeCode\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e31bd54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    06009\n",
      "1    30077\n",
      "2    41031\n",
      "3    41017\n",
      "4    15003\n",
      "Name: fipsFullCode, dtype: object\n",
      "0    0699009\n",
      "1    3099077\n",
      "2    4199031\n",
      "3    4199017\n",
      "4    1599003\n",
      "Name: fipsTribalCode, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Add to my df the fields I will need for comparison\n",
    "summaries_df[\"fipsFullCode\"] = summaries_df[\"fipsStateCode\"] + summaries_df[\"fipsCountyCode\"]\n",
    "summaries_df[\"fipsTribalCode\"] = summaries_df[\"fipsStateCode\"] + summaries_df[\"placeCode\"]\n",
    "\n",
    "print(summaries_df[\"fipsFullCode\"].head())\n",
    "\n",
    "print(summaries_df[\"fipsTribalCode\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5ff54",
   "metadata": {},
   "source": [
    "* Considering how I'm going to get the data from the API in shape for the comparison etc. I should just add the two additional columns I added manually for the dashboard I made first, COVID and Entity. After I add and calculate them, the comparisons will all be much easier, because I can just reference those fields for processing the data in chunks (i.e. step 1 process statewide, step 2 process counties, step 3 process tribal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f76cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good lord I can't remember how to calculate any of these fields with pandas... 🤣😭\n",
    "# Anyway the first one I need to calc is the COVID field, simple yes/no\n",
    "\n",
    "summaries_df[\"COVID-19\"] = np.where(summaries_df[\"declarationTitle\"].str.contains(\"COVID-19\"), \"Show only COVID-19\", \"Show only non-COVID-19\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba321596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>declarationTitle</th>\n",
       "      <th>COVID-19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [declarationTitle, COVID-19]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Okay why am I only getting threeeeeee COVID records with this...\n",
    "all_the_bugs = summaries_df[summaries_df[\"COVID-19\"] == \"Show only COVID-19\"][[\"declarationTitle\", \"COVID-19\"]]\n",
    "\n",
    "all_the_bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "320fdb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many records do I have...\n",
    "summaries_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b68776",
   "metadata": {},
   "source": [
    "* Right right right; I forgot that the API by default only returns 1000 records. I shouldn't really NEED more records than that, since the script is going to be run once per day. One thousand records should be MORE than enough. But, I now realize I need to do a little footwork to make sure I am just getting the 1000 _most recent_ records...\n",
    "\n",
    "Okay added a sort order to the api call to only get the most recent records by declarationDate! That should do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc69e8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2025-09-03T00:00:00.000Z\n",
       "1    2025-08-26T00:00:00.000Z\n",
       "2    2025-08-23T00:00:00.000Z\n",
       "3    2025-08-23T00:00:00.000Z\n",
       "4    2025-08-19T00:00:00.000Z\n",
       "Name: declarationDate, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_df[\"declarationDate\"].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arcgispro-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
